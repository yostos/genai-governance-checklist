# 付録: 強制力レベルの判断根拠

各チェック項目に付与した強制力レベル（Required / Recommended / Option）の
判断根拠を記載する。
ガイドライン作成者が自組織への適用可否を判断する際の参考資料として活用されたい。

判断の基本方針:

- **Required**: 欠落するとガイドラインとして機能しない、
  または法令違反・重大リスクに直結する項目
- **Recommended**: ガイドラインの実効性を高める重要な項目。
  除外する場合はその理由を説明できること
- **Option**: 記載があると望ましい項目。
  組織の規模や業種に応じて検討する

なお、本チェックリストの主な対象は
**専門のIT部門や技術者がいない小規模組織**である。
強制力レベルの判断にはこの前提が反映されている。

---

## 1. ガバナンス体制 (GOVERN)

### 1.1 組織体制・責任

| 項目 | レベル | 判断根拠 |
|------|--------|----------|
| 1.1.A. 最終責任者の明確化 | Required | ガバナンスの根幹。責任者不在ではインシデント時に判断が宙に浮く |
| 1.1.B. 担当部門・担当者の指定 | Required | 日常管理の起点。不在だと"野良AI"状態を招く |
| 1.1.C. 部門横断的な推進体制 | Recommended | 死角を防ぐ上で重要だが、小規模組織では外部専門家を含む体制構築が現実的に困難な場合がある |
| 1.1.D. 役割と責任の文書化 | Required | 責任の所在が曖昧だと機能不全に直結する。口頭合意は人事異動で失われる |
| 1.1.E. エスカレーションルート | Required | インシデント初動の遅れは被害拡大に直結する |
| 1.1.F. 多様な視点のチーム構成 | Option | 重要だが、小規模組織では人員構成上の制約が大きい。ベストプラクティスとしての位置づけ |

### 1.2 ポリシー・規程

| 項目 | レベル | 判断根拠 |
|------|--------|----------|
| 1.2.A. 目的・方針の明記 | Required | 目的のないガイドラインは形骸化する。文書の根幹 |
| 1.2.B. 適用範囲の明確化 | Required | 範囲が曖昧だと「自分は対象外」の逃げ道が生まれ、ガイドラインが機能しない |
| 1.2.C. 既存ポリシーとの整合性 | Required | 矛盾があると現場が混乱し、既存の情報セキュリティ体制まで崩れる |
| 1.2.D. 関連法令への言及 | Required | 法令に触れていなければ、知らずに法令違反を犯すリスクに直結 |
| 1.2.E. 定期的な見直し・更新 | Recommended | AI技術・法規制の変化は速く重要だが、仕組みの欠落が直ちに法令違反にはならない |
| 1.2.F. リスク許容度の定義 | Recommended | 判断の一貫性に寄与するが、小規模組織では暗黙の合意で運用できる場合もある |

### 1.3 教育・研修

| 項目 | レベル | 判断根拠 |
|------|--------|----------|
| 1.3.A. 従業員向け研修の計画 | Required | 読まれないガイドラインは存在しないのと同じ。研修なしでは実効性がない |
| 1.3.B. ITリテラシーレベル別教育 | Recommended | 効果的だが、小規模組織では全員同一研修でも最低限は機能する |
| 1.3.C. 新規利用者のオンボーディング | Required | 1.3.A（研修）がRequiredである以上、新規入職者がその研修を通らずにAIを使える状態はRequiredの抜け穴になる |
| 1.3.D. 継続的な啓発活動 | Recommended | 形骸化防止に重要だが、欠落が直ちに重大リスクにはならない |

### 1.4 監視・監査

| 項目 | レベル | 判断根拠 |
|------|--------|----------|
| 1.4.A. 利用状況のモニタリング | Option | 本来は必要だが、現状の主要SaaS型AIサービス（Claude、ChatGPT等）は会話内容レベルの管理者向け監視機能を提供しておらず、実現手段が限られる。利用量の確認やセルフチェックが現実的な対応 |
| 1.4.B. 定期的な監査・レビュー | Option | 1.4.Aのモニタリングが Option である以上、それを補完する位置づけの監査も同レベル |
| 1.4.C. 違反時の対応プロセス | Required | 場当たり的な対応はルールの信頼性を崩壊させる。公正な運用の基盤 |
| 1.4.D. インベントリ管理 | Recommended | 管理対象の可視化は重要だが、小規模でツール数が少なければ暗黙的に把握可能 |
| 1.4.E. サービス提供終了・重大変更時の対応方針 | Recommended | 業務停止リスクはあるが直ちに法令違反にはならない。平時からの備えとして推奨 |

---

## 2. リスクの特定と評価 (MAP)

### 2.1 利用目的・文脈の明確化

| 項目 | レベル | 判断根拠 |
|------|--------|----------|
| 2.1.A. 業務・ユースケースの特定 | Required | 利用対象が不明なままではリスク評価も効果測定もできない |
| 2.1.B. 期待効果の文書化 | Required | ユースケースの特定（A）とセットで導入の正当性を担保する |
| 2.1.C. 想定ユーザーと利用方法の定義 | Required | ユーザーにより入力データのリスクが異なる。リスク管理の前提 |
| 2.1.D. 使用すべきでない業務・場面の明記 | Required | 禁止ラインの明示がなければ重大リスク領域での誤用を防げない |
| 2.1.E. ビジネス価値・目的の定義 | Required | 「理事長がAIやろう」式の無計画導入を防ぐ。導入責任者は明確なビジネス価値を示すべき |
| 2.1.F. ミッション・目標との整合性確認 | Required | AI導入が組織の方向性と矛盾しないことの確認は基本要件 |

### 2.2 リスクの分類と評価

| 項目 | レベル | 判断根拠 |
|------|--------|----------|
| 2.2.A. 情報漏えいリスクの評価 | Required | 生成AI最大のリスク。何を投入してよいか評価・決定なしでの導入は論外 |
| 2.2.B. 著作権・知的財産権侵害リスクの評価 | Required | 法令違反に直結。文化庁見解でも依拠性推認の可能性あり |
| 2.2.C. ハルシネーションリスクの評価 | Required | 生成AIの構造的特性。評価なしでは誤情報の業務流入を防げない |
| 2.2.D. バイアス・公平性リスクの評価 | Recommended | 人事・評価での利用がなければ影響は限定的。利用形態に依存する |
| 2.2.E. プライバシーリスクの評価 | Required | 個人情報保護法に直結 |
| 2.2.F. セキュリティリスクの評価 | Required | AI固有の攻撃手法を理解しないまま導入するのは危険 |
| 2.2.G. 法的リスクの評価 | Required | 法令違反の認識欠如は免責にならない |
| 2.2.H. レピュテーションリスクの評価 | Recommended | 外部公開しない用途であれば影響は限定的 |
| 2.2.I. 業務依存リスクの評価 | Recommended | 重要だが、導入初期では影響が顕在化しにくい |
| 2.2.J. 環境負荷・サステナビリティの考慮 | Option | 望ましいが、小規模組織の利用量では実質的影響が小さい |

### 2.3 サードパーティリスク

| 項目 | レベル | 判断根拠 |
|------|--------|----------|
| 2.3.A. AIサービス・ツールの選定基準 | Required | 基準なしでは部門ごとにバラバラなツールが乱立し、リスク管理が崩壊する |
| 2.3.B. 利用規約・プライバシーポリシーの確認プロセス | Required | 規約未確認での導入は「学習利用あり」等の重大条項を見落とすリスク |
| 2.3.C. データの取り扱い（学習利用の有無等）の確認 | Required | 情報漏えいリスク評価（2.2.A）の具体的実行手段。学習利用の確認は最低限必須 |
| 2.3.D. サービス停止・変更時の対応策 | Recommended | 1.4.Eと関連。事業継続上重要だが、直ちに法令違反にはならない |
| 2.3.E. サプライチェーン全体でのリスク管理 | Option | 基盤モデル提供者の把握は望ましいが、小規模組織が実効的に管理するのは現実的に困難 |
