# 生成AI利用ガイドライン

一般社団法人 中小企業経営支援センター

---

## 文書管理情報

| 項目 | 内容 |
|------|------|
| 文書番号 | GL-AI-001 |
| バージョン | 1.0 |
| 制定日 | 2026年4月1日 |
| 施行日 | 2026年4月1日 |
| 承認者 | 理事長 山田太郎 |
| 次回見直し予定 | 2027年4月 |

[対応: 7.3.A, 7.3.B, 7.3.C, 7.3.D]

---

## はじめに ― このガイドラインについて

### このガイドラインの目的

近年、ChatGPTをはじめとする「生成AI」と呼ばれる技術が急速に普及しています。
生成AIは、文章の作成や翻訳、情報の整理など、私たちの業務を助けてくれる便利な道具です。

しかし、便利な道具には使い方のルールが必要です。
包丁は料理に欠かせませんが、使い方を誤れば怪我をします。
自動車は移動に便利ですが、交通ルールを守らなければ事故を起こします。
生成AIも同じです。

当センターは中小企業の皆様から経営に関するご相談をお受けしています。
ご相談の中には、売上や利益といった財務情報、従業員の情報、
取引先との契約内容など、外部に漏れてはならない大切な情報が含まれます。

もし職員が、こうした情報をうっかり生成AIに入力してしまったらどうなるでしょうか。
その情報はインターネットを通じて外部のサーバーに送られ、
最悪の場合、他の人の目に触れる可能性があります。
一度漏れた情報は、二度と取り戻すことができません。

また、生成AIは便利ですが、間違った情報をもっともらしく答えることがあります。
もし職員がAIの回答を鵜呑みにして、間違った情報をお客様に伝えてしまったら、
当センターの信頼は大きく損なわれるでしょう。

このガイドラインは、こうした事故を防ぎながら、
生成AIを業務に活かすためのルールを定めたものです。
「何が良くて、何がダメなのか」を明確にすることで、
職員の皆さんが安心してAIを使えるようにすることが目的です。

[対応: 1.2.A]

### このガイドラインが適用される範囲

このガイドラインは、当センターで働くすべての人に適用されます。
常勤・非常勤・嘱託職員を問いません。
また、業務で使用するすべての生成AIサービスが対象です。

「自分は事務作業だけだから関係ない」
「私はパソコンが苦手だからAIは使わない」
そう思う方もいるかもしれません。

しかし、AIは今後ますます身近になります。
使う・使わないに関わらず、このガイドラインの内容を知っておくことは、
組織の一員として大切なことです。

[対応: 1.2.B]

### 関連する法律について

生成AIを使う際には、いくつかの法律を守る必要があります。
難しく聞こえるかもしれませんが、要点だけ押さえておきましょう。

**個人情報保護法**
人の名前や住所、電話番号など、個人を特定できる情報を勝手に外部に出してはいけません。
生成AIに入力することは「外部に出す」ことと同じです。

**著作権法**
他人が作った文章や画像を勝手にコピーして使ってはいけません。
生成AIが作った文章が、既存の著作物と似ている場合も問題になることがあります。

**不正競争防止法**
会社の営業秘密を外部に漏らしてはいけません。
お客様の経営情報や契約内容は、この法律で保護されています。

法律の判断に迷ったときは、自分で判断せず、
AI管理担当者を通じて顧問弁護士に相談してください。

[対応: 1.2.D]

### 既存のルールとの関係

当センターには、すでに「情報セキュリティポリシー」と「個人情報保護方針」があります。
このガイドラインは、それらと矛盾しないように作られています。

生成AI特有のことは本ガイドラインに従い、
それ以外のことは既存のルールに従ってください。

[対応: 1.2.C]

---

## 用語の説明

このガイドラインで使う言葉の意味を説明します。
わからない言葉が出てきたら、ここに戻って確認してください。

[対応: 7.1.B]

### 生成AI（せいせいエーアイ）

人間が質問や指示を入力すると、文章や画像などを自動的に作り出すコンピュータプログラムです。
ChatGPT、Claude、Geminiなどが代表的なサービスです。

「AI」は「人工知能」の略で、コンピュータに人間のような判断をさせる技術の総称です。
「生成」は「作り出す」という意味で、文章や画像を作り出すAIを「生成AI」と呼びます。

### プロンプト

生成AIに対する質問や指示のことです。
たとえば「この文章を要約してください」「英語に翻訳してください」といった入力文がプロンプトです。

### ハルシネーション

生成AIが、事実ではない情報をもっともらしく回答することです。
「幻覚」という意味の英語から来ています。

たとえば、存在しない本のタイトルを作り上げたり、
実際には言っていない発言を有名人が言ったことにしたりします。
AIは「知らない」とは言わず、自信満々に嘘をつくことがあるのです。

### 機密情報（きみつじょうほう）

外部に漏らしてはいけない大切な情報のことです。
当センターでは、お客様の経営情報、未公開の事業計画、
内部の人事情報などが該当します。

### 個人情報（こじんじょうほう）

特定の個人を識別できる情報のことです。
氏名、住所、電話番号、メールアドレス、生年月日などが該当します。
これらの情報は、単独でも組み合わせでも個人を特定できるため、慎重に扱う必要があります。

### 要配慮個人情報（ようはいりょこじんじょうほう）

個人情報の中でも、特に慎重な取り扱いが必要な情報です。
病歴、障害の有無、犯罪歴、信条（宗教や政治的な考え）などが該当します。
これらは差別につながる恐れがあるため、法律で特別に保護されています。

---

## 第1章　組織の体制と役割

生成AIを安全に使うためには、「誰が何を担当するのか」を明確にしておく必要があります。
問題が起きたときに「それは私の担当ではない」と言い合っていては、対応が遅れます。

[対応: 1.1.D]

### 役割と責任

当センターでは、以下の体制でAI利用を管理します。

**AI利用最終責任者：理事長**

生成AI利用に関する最終的な判断を行います。
重大な問題が起きたとき、最終的に責任を取るのは理事長です。
「AIのことは担当者に任せている」では済まされません。
理事長自身が、AIの利用状況やリスクを把握している必要があります。

[対応: 1.1.A]

**AI管理責任者：総務部長**

AI利用の実務面での責任者です。
どのAIサービスを使うか、予算をどうするかといった判断を行います。
問題が発生したときは、理事長に報告し、対応を指揮します。

**AI管理担当者：総務部担当者**

日常的なAI管理の窓口です。
職員からの質問に答えたり、研修を企画したり、
問題の一次対応を行ったりします。
「AIのことでわからないことがあったら、まずこの人に聞く」という存在です。

[対応: 1.1.B]

**利用者：全職員**

このガイドラインを守り、適切にAIを利用する責任があります。
「ルールを知らなかった」は言い訳になりません。

### 連携の体制

AI利用は、技術の問題だけでなく、法律の問題、業務の問題も絡みます。
そのため、総務部だけでなく、各事業部門、そして外部の専門家
（顧問弁護士、ITコンサルタント）とも連携して対応します。

判断に迷う案件は、一人で抱え込まず、関係者で相談して決めましょう。

[対応: 1.1.C]

### 問題が起きたときの連絡ルート

AIに関する問題を発見したら、以下の順番で報告してください。

1. **まず、AI管理担当者に連絡**
   電話でも、メールでも、チャットでも構いません。
   「こんなことが起きました」とすぐに伝えてください。

2. **AI管理担当者からAI管理責任者へ**
   担当者は30分以内に責任者（総務部長）へ報告します。

3. **必要に応じて最終責任者へ**
   重大な問題の場合は、理事長に報告し、判断を仰ぎます。

「大したことないかも」と思っても、自分で判断せず報告してください。
小さな問題が大きくなる前に対処することが大切です。

[対応: 1.1.E]

---

## 第2章　使ってよいAIサービス

### 承認されたサービス

当センターで業務に使用してよい生成AIサービスは、以下の通りです。

- **ChatGPT Team**（OpenAI社）
- **Claude**（Anthropic社）
- **Gemini**（Google社）

これらは、当センターが安全性を確認し、正式に利用を認めたサービスです。

[対応: 5.3.A, 1.4.D]

### なぜ「承認されたサービス」だけなのか

インターネット上には、無料で使える生成AIサービスがたくさんあります。
「無料だし、便利そうだから使ってみよう」と思うかもしれません。

しかし、無料のサービスには落とし穴があることがあります。
入力した情報が、サービス提供者に利用されたり、
他のユーザーへの回答に使われたりする可能性があります。

承認されたサービスは、そうしたリスクを確認した上で選んでいます。
それ以外のサービスを勝手に使うと、情報漏えいの原因になりかねません。

### 承認されていないサービスは使用禁止

上記のリスト以外のAIサービスを業務で使うことは禁止です。

また、個人で契約しているAIサービス（プライベートで使っているChatGPTなど）に
業務のデータを入力することも禁止です。
プライベートと業務は明確に分けてください。

新しいサービスを使いたい場合は、AI管理責任者に申請してください。
安全性を確認した上で、承認リストに追加するかどうかを判断します。

[対応: 5.3.B]

### アカウントの管理

AIサービスのアカウント（ログインID）は、一人につき一つです。
「ちょっと貸して」と同僚にIDを貸したり、共有したりしてはいけません。

なぜでしょうか。
問題が起きたとき、「誰がいつ何を入力したか」を確認する必要があります。
アカウントを共有していると、それがわからなくなってしまいます。

パスワードは組織のルールに従って設定し、
二段階認証（ログイン時にスマホに確認コードが届く仕組み）が
使える場合は、必ず設定してください。

[対応: 5.3.C]

---

## 第3章　AIを使ってよい業務

### 利用を認める業務

以下の業務では、生成AIを積極的に活用してください。

**1. 文書の草稿作成**
報告書、提案書、メールなどの下書きを作ってもらう。
ただし、AIが作った文章はそのまま使わず、必ず自分で確認・修正すること。

**2. 調査・情報収集の補助**
業界動向を調べたり、制度の概要を把握したりする際の参考にする。
ただし、AIの回答は必ず公式な情報源で確認すること。

**3. 翻訳・要約の支援**
英語の資料を日本語に訳したり、長い文書の要点をまとめたりする。
専門的な内容は、専門家に確認すること。

**4. アイデア出し**
新しい企画を考えるときや、問題解決の糸口を探すときのヒントにする。

[対応: 2.1.A]

### これらの業務に期待する効果

| 業務 | 期待する効果 |
|------|-------------|
| 文書の草稿作成 | 作成時間の短縮、表現の幅を広げる |
| 調査・情報収集 | 情報収集の効率化、調査の出発点を得る |
| 翻訳・要約 | 多言語対応力の向上、長文の理解促進 |
| アイデア出し | 発想の幅を広げる、検討の漏れを減らす |

半年ごとに、実際に効果があったかを振り返り、使い方を見直します。

[対応: 2.1.B, 2.1.E, 2.1.F]

### 主に使う人

現時点では、事務職員と相談支援部の職員が主な利用者です。
各自の担当業務の範囲内でAIを活用してください。

他部門の業務データを使いたい場合は、必ずその部門の了承を得てください。

[対応: 2.1.C]

### AIを使ってはいけない業務

以下の業務では、生成AIを使ってはいけません。

**1. 人の評価に関わる判断**
人事評価、採用選考、昇進の判断など。
AIには偏り（バイアス）があり、公平な判断ができない可能性があります。
人の人生に関わる判断を機械に任せてはいけません。

**2. 法的効力を持つ文書の最終作成**
契約書、公式な声明文など。
AIが作った文章には誤りが含まれている可能性があり、
法的なトラブルにつながる恐れがあります。

**3. 外部への正式な回答**
お客様への最終的な助言、メディアへの公式コメントなど。
組織の名前で外に出す言葉は、人間が責任を持って作成・確認すべきです。

**4. 顧客への最終的な助言・提案**
AIの下書きを参考にすることはできますが、
お客様に伝える内容は、必ず人間が判断・確認してから伝えてください。

[対応: 2.1.D]

---

## 第4章　AIに入力してはいけない情報

この章は、このガイドラインで最も重要な部分です。
何度も読み返して、しっかり頭に入れてください。

### なぜ入力してはいけない情報があるのか

生成AIに入力した情報は、インターネットを通じて
サービス提供者のコンピュータ（サーバー）に送られます。
そのサーバーは、多くの場合、海外（アメリカなど）にあります。

つまり、AIに情報を入力するということは、
**その情報を海外のコンピュータに送っている**ということです。

一度送った情報は、完全には消せません。
お客様の大切な情報が、外部に出てしまってからでは取り返しがつきません。
だから、「入力してはいけない情報」を明確に決めているのです。

[対応: 3.1.A]

### 入力禁止リスト

以下の情報は、**絶対に**生成AIに入力しないでください。
迷ったときは、入力せずにAI管理担当者に相談してください。

---

**【1】個人情報**

氏名、住所、電話番号、メールアドレス、生年月日、マイナンバーなど、
個人を特定できる情報は入力禁止です。

「名前だけなら大丈夫かな」と思うかもしれませんが、
名前と会社名を組み合わせれば、その人が誰かわかってしまいます。
複数の情報を組み合わせると個人が特定できることを忘れないでください。

**例：これはダメ**
「田中一郎さん（03-1234-5678）への提案書を書いて」

**例：これならOK**
「クライアントへの提案書の書き方を教えて」

[対応: 3.1.B]

---

**【2】機密情報**

営業秘密、未公開の事業計画、非公開の研究データなどは入力禁止です。

当センターの内部情報だけでなく、
お客様から預かった経営情報も当然含まれます。

**例：これはダメ**
「A社の来期の売上目標は5億円で、新規事業として〇〇を計画しています。
この戦略についてアドバイスをください」

**例：これならOK**
「中小企業が新規事業を始める際の一般的な注意点を教えて」

[対応: 3.1.C]

---

**【3】顧客情報**

取引先の名前、契約条件、見積金額、顧客固有の業務情報などは入力禁止です。

お客様から「御社だから」と信頼して預けていただいた情報です。
それをAIに入力することは、その信頼を裏切る行為です。

どうしても参考にしたい場合は、会社名を伏せて
「製造業のX社」「従業員50名のY社」のように一般化してください。

[対応: 3.1.D]

---

**【4】認証情報**

パスワード、APIキー、アクセストークンなど、
システムにログインするための情報は入力禁止です。

「エラーが出たので原因を調べて」とAIに頼むとき、
うっかりパスワードが含まれた画面を見せてしまうことがあります。
入力前に、認証情報が含まれていないか必ず確認してください。

[対応: 3.1.E]

---

**【5】財務情報**

未公開の決算情報、予算、投資計画などは入力禁止です。

これらが漏れると、法律違反（インサイダー取引など）につながる恐れがあります。

[対応: 3.1.F]

---

**【6】人事情報**

人事評価、給与、賞与、健康診断の結果、休職情報などは入力禁止です。

特に、病歴、障害の有無、信条などの「要配慮個人情報」は、
**絶対に**入力してはいけません。
これらは法律で特別に保護されている情報です。

[対応: 3.1.G]

---

**【7】法的に保護された情報**

弁護士との相談内容、訴訟に関する文書などは入力禁止です。

弁護士との相談内容には「秘匿特権」という法的保護があります。
AIに入力することで、その保護を失う可能性があります。

[対応: 3.1.H]

---

### 情報の分類と判断基準

「この情報は入力していいのかな？」と迷ったときは、
以下の表を参考に判断してください。

| 情報の種類 | AIへの入力 | 例 |
|-----------|-----------|-----|
| 公開情報 | OK | 公開されているニュース、一般的な制度の説明 |
| 社内限定情報 | 匿名化すればOK | 社内の業務マニュアル（固有名詞を消す） |
| 機密情報 | 禁止 | 顧客情報、財務情報、人事情報 |

[対応: 3.2.A]

### 匿名化の方法

「匿名化すればOK」と言われても、どうすればよいかわからないかもしれません。
以下の手順で行ってください。

1. **個人名を仮名に**
   「田中一郎」→「A氏」「担当者」など

2. **組織名を一般名称に**
   「株式会社〇〇」→「X社」「製造業の中小企業」など

3. **住所・電話番号・メールアドレスを削除**
   これらは残しておく必要がほとんどありません

4. **最終確認**
   これらを組み合わせても個人や組織が特定できないか確認

[対応: 3.2.B]

### 他社から預かった情報

取引先やお客様から預かった情報は、自社の情報以上に慎重に扱ってください。
原則として、他者から預かった情報はAIに入力しません。

どうしても入力が必要な場合は、
その情報に適用される守秘義務の範囲を確認し、
必要に応じて情報の提供元の了承を得てください。

[対応: 3.2.C, 3.2.D]

### 個人情報とAI

個人情報をAIに入力することは、
法律上「個人データの第三者提供」にあたる可能性があります。
これには本人の同意が必要な場合があります。

難しい話に聞こえるかもしれませんが、
要するに「個人情報はAIに入力しない」と覚えておけば問題ありません。

[対応: 3.3.A, 3.3.B, 3.3.C]

### 海外サーバーの問題

現在使用しているAIサービスは、すべて海外のサーバーで動いています。
個人情報を海外に送ることには、法律上の追加的な制限があります。

このため、**個人情報のAIへの入力は原則禁止**としています。

[対応: 3.3.D]

### 必要最小限の情報だけを入力

AIに何かを頼むときは、目的に必要な最小限の情報だけを入力してください。

「念のため、関連しそうな情報も全部入れておこう」はダメです。
不要な情報を入力すれば、それだけ漏えいのリスクが高まります。

[対応: 5.6.B]

---

## 第5章　AIの出力を使うときの注意

AIが出力した文章や情報を使うときにも、守るべきルールがあります。

### AIは間違える

これが最も重要な点です。
**AIは、間違った情報を自信満々に答えることがあります。**

AIは「わかりません」とは言いません。
知らないことでも、もっともらしい答えを作り出します。
これを「ハルシネーション（幻覚）」と呼びます。

存在しない法律を引用したり、
実際にはない研究結果を紹介したり、
嘘の統計データを提示したりすることがあります。

「AIが言っているから正しいだろう」と思ってはいけません。
**AIの回答は、必ず確認が必要です。**

[対応: 5.1.A]

### AIの苦手なこと

AIは万能ではありません。以下のことは特に苦手です。

**最新の情報**
AIの知識は、学習した時点で止まっています。
最新のニュースや、最近変わった法律などは知りません。

**正確な計算**
複雑な計算は間違えることがあります。
数字が重要な場面では、必ず自分で検算してください。

**専門的な判断**
法律の解釈、医学的な判断、技術的な専門知識など、
高度な専門性が必要な内容は間違えやすいです。

**ローカルな情報**
地元の店舗情報、組織内部の事情など、
一般に公開されていない情報は知りません。

[対応: 5.1.B]

### 出力の信頼度の目安

| AIの出力内容 | 信頼度 | どうするか |
|-------------|--------|-----------|
| 一般的な知識の要約、翻訳 | 比較的高い | 確認は必要だが、大きく間違えることは少ない |
| 専門分野の情報、最新情報 | 低い | 必ず専門家や公式情報で確認 |
| 数字、人名、固有名詞 | 低い | 必ず一次情報で確認 |

[対応: 5.1.C]

### ファクトチェック（事実確認）

AIの出力を業務に使う前に、事実関係を確認してください。

特に以下の情報は、必ず元の情報源で裏を取ってください。

- 数値（売上、統計など）
- 日付
- 法令名
- 人名
- 会社名や組織名

確認が難しい情報は、「AI出力のため未検証」と明示してください。

[対応: 4.1.A]

### 専門家の確認が必要な場合

AIの出力が以下の分野に関わる場合は、専門家の確認を受けてください。

| 分野 | 確認を依頼する人 |
|------|-----------------|
| 法律・契約 | 顧問弁護士 |
| 財務・会計 | 顧問税理士 |
| 技術的な内容 | ITコンサルタント |

「たぶん大丈夫だろう」で進めると、後で大きな問題になることがあります。

[対応: 4.1.B]

### そのまま使ってはいけない場面

以下の場面では、AIの出力をそのまま使うことを禁止します。
必ず人間が加筆・修正し、内容を確認してから使ってください。

- **契約書、公式な声明文**
  法的効力を持つ文書にAIの誤りがあると、大きな問題になります

- **人事評価や処遇に関する文書**
  人の人生に関わる判断にAIを使うのは不適切です

- **お客様への最終的な助言・提案**
  当センターの名前で出すものは、人間が責任を持つべきです

- **報道機関への公式コメント**
  組織を代表する発言にAIの誤りは許されません

[対応: 4.1.C, 5.2.A, 5.2.B]

### 承認のプロセス

AIの出力を使う場合、利用場面に応じて確認・承認を受けてください。

| 利用場面 | 必要な手続き |
|----------|-------------|
| 自分の参考用（社内メモなど） | 自分で確認すればOK |
| 社外に出す資料 | 上長の承認が必要 |
| 重要な意思決定に使う | AI管理担当者にも確認 |

[対応: 4.1.D, 4.4.A]

### 著作権について

AIが作った文章や画像は、既存の著作物に似ていることがあります。
AIは大量の文章や画像を学習しているため、
学習元と似たものを出力してしまうことがあるのです。

他人の著作物と似たものを使うと、著作権侵害になる可能性があります。

**対策**
- 画像は、Google画像検索などで似た画像がないか確認する
- 文章は、特徴的な表現が他の文献と一致しないか確認する
- 不安な場合は使用を控える

[対応: 4.2.A, 4.2.B]

### AI生成であることの表示

社外向けの資料にAI出力を使った場合は、
その旨を明示することを推奨します。

例：「本文書の草案作成にAIを利用しています」

また、お客様への提出物にAIを使った場合、
聞かれたら正直にAI利用を説明できるようにしてください。
「AIを使ったことを隠す」のは信頼を損なう行為です。

[対応: 4.3.A, 4.3.B, 4.3.C]

### 根拠を説明できるようにする

AIを使って意思決定を行った場合、
「AIがこう言ったから」は説明になりません。

「AIの出力をどう参考にして、どう判断したのか」を
関係者に説明できるようにしてください。

説明が難しい場合は、その出力を判断の主な根拠にしないでください。
他の情報源でも裏付けを取りましょう。

[対応: 5.4.B, 5.5.A, 5.5.B]

---

## 第6章　リスクへの対応

生成AIを使うことには、さまざまなリスクがあります。
当センターでは、これらのリスクを認識した上で対策を講じています。

### 主なリスクと対策

**情報漏えいリスク**
入力した情報が外部に漏れるリスク。
→ 入力禁止情報を明確化、個人データの入力を原則禁止

**誤情報のリスク（ハルシネーション）**
AIが間違った情報を出力し、それを信じてしまうリスク。
→ ファクトチェックの義務化、専門家レビュー

**著作権侵害リスク**
AI出力が既存の著作物と類似し、著作権を侵害するリスク。
→ 類似性の確認、出典の明記

**偏り（バイアス）のリスク**
AIの出力に性別、人種、年齢などの偏りが含まれるリスク。
→ 人事・評価での利用制限、バイアスへの注意喚起

**業務への過度な依存リスク**
AIに頼りすぎて、AIなしでは業務ができなくなるリスク。
→ AIなしでも業務できる体制の維持

[対応: 2.2.A〜I]

### AIサービスの選定と確認

AIサービスを導入する際は、以下を確認しています。

- 入力データがAIの学習に使われるかどうか
- データがどこに保存されるか
- セキュリティ対策は十分か
- 利用規約に問題はないか

[対応: 2.3.A, 2.3.B, 2.3.C]

### サービスが使えなくなったときの備え

AIサービスが突然終了したり、大幅に変更されたりする可能性があります。
そのために、以下の備えをしています。

- 代替となるサービスの候補を把握しておく
- 重要な業務はAIなしでも遂行できる手順を維持する

サービスに問題が発生したら、
AI管理担当者が48時間以内に代替策を提示します。

[対応: 2.3.D, 1.4.E]

### セキュリティへの注意

外部から取得したテキスト（Webページ、メールの文面など）を
AIに入力する際は注意してください。

悪意のある人が、AIをだますための指示を
テキストの中に隠していることがあります
（「プロンプトインジェクション」と呼ばれます）。

AIが急に変な回答をしたり、
今までと違う動作をしたりした場合は、
利用を中止してAI管理担当者に報告してください。

[対応: 5.3.D]

### バイアス（偏り）について

AIの回答には、学習データに含まれる偏りが反映されることがあります。

例えば、「社長」と言うと男性を想定したり、
「看護師」と言うと女性を想定したりすることがあります。
これは社会に存在する偏見がAIにも反映されているためです。

AIの出力を評価や判断に使う際は、
こうした偏りがないか意識してください。

特に、人事評価や採用に関わる場面でAIを使う場合は、
AIの出力を唯一の判断基準にせず、
必ず人間が複数の視点から判断してください。

[対応: 5.7.A, 5.7.B]

---

## 第7章　教育と研修

ガイドラインは、読んでもらわなければ意味がありません。
当センターでは、以下の研修を実施します。

### 初回研修（全員必須）

生成AIの利用を開始する前に、
全職員を対象とした初回研修（90分）を受けてください。

**内容**
- このガイドラインの要点
- 入力してはいけない情報の具体例
- AIの限界と注意点
- 問題が起きたときの報告方法

受講していない人には、AIサービスのアカウントを発行しません。
研修を受けるまで、AIは使えません。

[対応: 1.3.A]

### レベル別の研修

ITに詳しい人もいれば、パソコンが苦手な人もいます。
全員に同じ研修をしても、効果は限られます。

そのため、基礎編と実践編の2段階で研修を行います。

| 研修 | 対象 | 内容 |
|------|------|------|
| 基礎編 | 全職員 | AIの概要、リスク、禁止事項 |
| 実践編 | 日常的にAIを使う人 | 効果的な使い方、よくある失敗例 |

[対応: 1.3.B]

### 新しく入った人への対応

新しく入職した方には、入職時のオリエンテーションで
このガイドラインの説明を行います。

研修を受けてから、AIサービスのアカウントを発行します。
「先輩に聞きながら使い始める」はNGです。

[対応: 1.3.C]

### 継続的な情報共有

四半期に1回（3か月に1回）、
AI利用に関するミニ勉強会（30分程度）を行います。

**内容**
- 最近のニュースや事例の紹介
- うまくいった活用例の共有
- よくある質問への回答
- ガイドラインの改訂内容の説明

また、他社で大きなAI関連のトラブルがあった場合は、
臨時で注意喚起のメールを配信します。

[対応: 1.3.D]

---

## 第8章　問題が起きたとき

### 「インシデント」とは

以下のような問題を「インシデント」と呼びます。
これらが起きたら、すぐに報告してください。

1. **入力禁止の情報をAIに入力してしまった**
   例：うっかりお客様の名前と電話番号を入力した

2. **AIの誤った情報を確認せずに社外に出してしまった**
   例：AIの回答をそのまま使って、お客様に間違った情報を伝えた

[対応: 6.1.A]

### 問題が起きたらすぐにやること

慌てないでください。落ち着いて、以下の手順で対応してください。

**1. AIの利用をいったん止める**
これ以上の被害を防ぐため、まずそのAIの利用を止めてください。

**2. 状況を把握する**
何を入力したのか、何を出力したのか、
それを誰に見せた・送ったのかを確認してください。

**3. AI管理担当者に報告する**
わかった範囲で、すぐに報告してください。
「全部わかってから報告しよう」と思わないでください。
時間が経つほど対応が難しくなります。

**4. 指示に従って対応する**
AI管理担当者からの指示に従い、
必要な措置（訂正の連絡、データの回収など）を行ってください。

[対応: 6.2.A]

### 外部への報告が必要な場合

以下の場合は、外部への報告が必要になることがあります。
これらの判断はAI管理責任者が行いますので、
まずは社内に報告してください。

- 個人情報が漏れた可能性がある
  → 個人情報保護委員会への報告が法律で義務付けられています

- お客様に間違った情報を伝えた
  → お客様への訂正連絡が必要です

- AIサービスの利用規約に違反した可能性がある
  → サービス提供者への確認が必要です

[対応: 6.2.B]

### 記録と改善

インシデントが起きたら、以下を記録します。

- いつ起きたか
- 何が起きたか
- どう対応したか
- なぜ起きたのか

これらの記録は、同じ問題を繰り返さないために使います。
似たような問題が何度も起きるなら、ガイドラインの改訂を検討します。

[対応: 6.3.A]

### 緊急停止が必要な場合

以下の場合は、AI利用を即座に停止します。
「様子を見よう」はNGです。

- 情報漏えいの疑いがある
- AIサービスの利用規約が大幅に変更された
- AIが繰り返しおかしな出力をする

停止の判断はAI管理責任者が行います。

[対応: 5.2.C]

---

## 第9章　ルールを破った場合

### 違反への対応

このガイドラインに違反した場合、以下の対応を行います。

**軽微な違反の場合**
例：うっかり入力禁止情報を入力してしまった（すぐに報告した）

- 口頭での注意
- 再研修の受講

**重大な違反の場合**
例：意図的に顧客情報を入力した、繰り返し違反した

- AI利用権限の停止
- 就業規則に基づく懲戒処分

「知らなかった」「悪気はなかった」は理由になりません。
このガイドラインを読み、研修を受けた以上、
ルールを守る責任があります。

[対応: 1.4.C]

---

## 第10章　ガイドラインの運用

### 定期的な見直し

このガイドラインは、少なくとも年1回（毎年4月）に見直します。

AI技術は急速に進歩しており、法律や社会の状況も変わります。
一度作ったルールを永遠に使い続けることはできません。

また、大きな法改正があった場合や、
重大なインシデントが発生した場合は、臨時で見直しを行います。

見直しはAI管理担当者が起案し、最終責任者が承認します。

[対応: 1.2.E]

### リスクの許容範囲

どの程度のリスクなら許容するかを、以下のように定めています。

| リスクの程度 | AI利用 |
|-------------|--------|
| 低リスク（公開情報の整理など） | 積極的に活用 |
| 中リスク（社内文書の作成など） | 注意して利用 |
| 高リスク（機密情報、個人情報を扱う業務） | 利用を制限または禁止 |

判断に迷う場合は、AI管理担当者に相談してください。

[対応: 1.2.F]

### 例外への対応

業務上やむを得ず、ガイドラインの例外を認める必要がある場合は、
以下の手順で申請してください。

1. AI管理担当者に相談
2. 最終責任者の承認を得る
3. 例外の内容と理由を記録

なし崩し的に「特別扱い」が広がらないよう、
例外は必ず記録し、次回の見直し時に検討します。

[対応: 7.2.D]

---

## 問い合わせ先

このガイドラインについて質問がある場合、
判断に迷う場合は、以下に連絡してください。

| 担当 | 連絡先 |
|------|--------|
| AI管理担当者 | 総務部 ○○（内線: XXX、メール: ai-support@example.or.jp） |
| AI管理責任者 | 総務部長 △△（内線: YYY） |

「こんなこと聞いていいのかな」と思わずに、
気軽に質問してください。
聞かずに間違えるより、聞いて正しく使う方がずっと良いです。

[対応: 7.2.A, 7.2.B, 7.2.C]

### 関連する文書

- 情報セキュリティポリシー
- 個人情報保護方針
- 就業規則

[対応: 7.1.D]

---

## 改訂履歴

| 版 | 改訂日 | 改訂内容 |
|----|--------|----------|
| 1.0 | 2026年4月1日 | 初版制定 |

[対応: 7.3.A]

---

**以上**

このガイドラインを守り、安全にAIを活用しましょう。
わからないことがあれば、いつでもAI管理担当者に相談してください。
