# 生成AI利用ガイドライン

一般社団法人 中小企業経営支援センター

---

## 文書管理情報

| 項目 | 内容 |
|------|------|
| 文書番号 | GL-AI-001 |
| バージョン | 1.0 |
| 制定日 | 2026年4月1日 |
| 施行日 | 2026年4月1日 |
| 承認者 | 理事長 山田太郎 |
| 次回見直し予定 | 2027年4月 |

[対応: 7.3.A, 7.3.B, 7.3.C, 7.3.D]

---

## 目次

1. [目的](#1-目的)
2. [適用範囲](#2-適用範囲)
3. [用語の定義](#3-用語の定義)
4. [組織体制と責任](#4-組織体制と責任)
5. [利用の基本方針](#5-利用の基本方針)
6. [入力データの管理](#6-入力データの管理)
7. [出力の管理](#7-出力の管理)
8. [教育・研修](#8-教育研修)
9. [インシデント対応](#9-インシデント対応)
10. [違反時の対応](#10-違反時の対応)
11. [運用・見直し](#11-運用見直し)
12. [問い合わせ先](#12-問い合わせ先)
13. [改訂履歴](#13-改訂履歴)

[対応: 7.1.A]

---

## 1. 目的

本ガイドラインは、当センターにおける生成AIの利用について、
業務効率の向上と創造性の支援を目的として基本方針を定める。
AIはあくまで人間の判断を補助するツールとして位置づけ、
最終的な意思決定は人間が行う。

[対応: 1.2.A]

### 関連法令

生成AIの利用にあたっては、以下の法令を遵守する：

- 個人情報保護法
- 著作権法
- 不正競争防止法
- 人工知能関連技術の研究開発及び活用の推進に関する法律（AI推進法）

法的判断に迷う場合は、AI管理担当者を通じて顧問弁護士に相談する。

[対応: 1.2.D]

### 既存規程との関係

本ガイドラインは、既存の情報セキュリティポリシー及び個人情報保護方針と
整合性を確認済みである。AI固有の事項については本ガイドラインが優先し、
記載のない事項は既存ポリシーに従う。

[対応: 1.2.C]

---

## 2. 適用範囲

本ガイドラインは、当センターのすべての役職員
（常勤・非常勤・嘱託職員を含む）が、
業務上利用するすべての生成AIサービスに適用する。

[対応: 1.2.B]

---

## 3. 用語の定義

| 用語 | 定義 |
|------|------|
| 生成AI | テキスト、画像等を生成する人工知能システム。ChatGPT、Claude、Gemini等 |
| ハルシネーション | 生成AIが事実に基づかない情報をもっともらしく出力すること |
| プロンプト | 生成AIへの指示・質問文 |
| 機密情報 | 営業秘密、未公開情報、戦略情報等、外部への開示が制限される情報 |
| 個人情報 | 特定の個人を識別できる情報 |
| 要配慮個人情報 | 病歴、信条、犯罪歴等、特に慎重な取扱いを要する個人情報 |

[対応: 7.1.B]

---

## 4. 組織体制と責任

### 4.1 役割と責任

| 役割 | 担当 | 責任範囲 |
|------|------|----------|
| AI利用最終責任者 | 理事長 | 方針承認、重大インシデント時の意思決定 |
| AI管理責任者 | 総務部長 | 財源確保、サービス選定、成果責任 |
| AI管理担当者 | 総務担当者 | 日常管理、問い合わせ対応、研修企画 |
| 利用者 | 全職員 | ガイドライン遵守、適切な利用 |

[対応: 1.1.A, 1.1.B, 1.1.D]

### 4.2 連携体制

AI利用に関する方針検討・リスク判断は、
総務部（管理）・各事業部門・外部顧問（法務・IT）が連携して行う。

[対応: 1.1.C]

### 4.3 エスカレーションルート

AIに関する問題を発見した場合は、以下の手順で報告する：

1. 発見者 → AI管理担当者（即時報告）
2. AI管理担当者 → AI管理責任者（30分以内）
3. AI管理責任者 → 最終責任者（重大な場合）

[対応: 1.1.E]

---

## 5. 利用の基本方針

### 5.1 利用を認める業務

以下の業務での生成AI利用を認める：

1. 文書の草稿作成（報告書、提案書等）
2. 調査・情報収集の補助
3. 翻訳・要約の支援
4. アイデア出し・ブレインストーミング

上記以外の業務での利用はAI管理担当者の事前承認を要する。

[対応: 2.1.A]

### 5.2 期待する効果

| ユースケース | 期待する効果 |
|--------------|--------------|
| 文書草稿作成 | 作成時間の短縮 |
| 調査補助 | 情報収集の効率化 |
| 翻訳・要約 | 多言語対応力の向上 |

効果は半年ごとに検証する。

[対応: 2.1.B, 2.1.E]

### 5.3 想定利用者

主な利用者は事務職員および相談支援部職員とする。
各利用者は自身の業務範囲内でのみAIを利用する。

[対応: 2.1.C]

### 5.4 利用を禁止する業務

以下の業務・場面ではAI利用を禁止する：

- 個人の評価・処遇に関する判断
- 法的効力を持つ文書の最終作成
- 外部への正式な回答・声明の作成
- 顧客への最終的な助言・提案（草案作成は可）

[対応: 2.1.D]

### 5.5 組織目標との整合性

生成AIの利用方針が当センターの事業計画・行動指針と
整合していることを、年次の方針見直し時に確認する。

[対応: 2.1.F]

### 5.6 承認済みAIサービス

利用を承認するAIサービスは以下の通り：

- ChatGPT Team（OpenAI）
- Claude（Anthropic）
- Gemini（Google）

新たなサービスの追加はAI管理責任者の承認を経ること。

[対応: 5.3.A, 1.4.D]

### 5.7 未承認サービスの禁止

承認リストに記載のないAIツール・サービスの業務利用は禁止する。
個人契約のAIサービスを業務データで使用することも禁止する。

[対応: 5.3.B]

### 5.8 アカウント管理

- AIサービスのアカウントは1人1つとし、共有を禁止する
- パスワードは組織のポリシーに従う
- 多要素認証が利用可能な場合は必ず有効にする

[対応: 5.3.C]

---

## 6. 入力データの管理

### 6.1 入力禁止情報

以下の情報は生成AIへの入力を禁止する。
判断に迷う場合はAI管理担当者に確認すること。

[対応: 3.1.A]

#### 個人情報
氏名、住所、電話番号、メールアドレス、生年月日、マイナンバー等。
匿名化（仮名への置き換え等）した上であれば利用可。

[対応: 3.1.B]

#### 機密情報
営業秘密、未公開の事業戦略・製品情報、非公開の研究データ等。

[対応: 3.1.C]

#### 顧客情報
取引先名、契約条件、見積金額、顧客固有の業務情報等。
顧客情報を参照する必要がある場合は、固有名を伏せた上で利用する。

[対応: 3.1.D]

#### 認証情報
パスワード、APIキー、アクセストークン、秘密鍵等は絶対に入力しない。

[対応: 3.1.E]

#### 財務情報
未公開の決算情報、予算情報、投資計画等。

[対応: 3.1.F]

#### 人事情報
人事評価、給与、賞与、健康診断結果、休職情報等。
特に要配慮個人情報（病歴、信条、犯罪歴等）は絶対に入力しない。

[対応: 3.1.G]

#### 法的保護情報
弁護士との相談内容、訴訟関連文書、法的秘匿特権の対象となる情報。

[対応: 3.1.H]

### 6.2 機密度分類と利用可否

| 分類 | AI入力可否 |
|------|------------|
| 公開情報 | 可 |
| 社内限定情報 | 匿名化処理後に可 |
| 機密情報 | 不可 |

[対応: 3.2.A]

### 6.3 匿名化の手順

AI入力前の匿名化手順：

1. 個人名 → 仮名（A氏、B氏等）に置換
2. 組織名 → 一般名称（X社等）に置換
3. 住所・電話番号・メールアドレスを削除
4. 複数情報の組合せで個人が特定されないことを確認

[対応: 3.2.B]

### 6.4 第三者情報の取扱い

第三者から受領した情報は、原則としてAIに入力しない。
やむを得ず入力する場合は、守秘義務の範囲を確認し、
必要に応じて情報提供元の承諾を得る。

[対応: 3.2.C, 3.2.D]

### 6.5 個人データの取扱い

個人データは原則としてAIに入力しない。
業務上やむを得ない場合は：

1. 匿名化処理を行う
2. 匿名化が困難な場合はAI管理担当者の承認を得る

[対応: 3.3.A]

### 6.6 本人同意

個人情報をAIに入力する場合、既存のプライバシーポリシーで
AI利用が利用目的に含まれているかを確認する。
含まれていない場合は、ポリシー改定または個別同意を取得する。

[対応: 3.3.B]

### 6.7 委託の該当性

AIサービスへの個人データ入力が「委託」に該当するかを、
サービスの利用形態に基づき判断する。
委託に該当する場合は、委託先の管理体制を確認し、必要な契約を締結する。

[対応: 3.3.C]

### 6.8 越境移転への対応

現在利用している生成AIサービスは海外サーバーで処理されるため、
個人データの入力は原則禁止とする。

[対応: 3.3.D]

### 6.9 データ最小化

生成AIへの入力は業務目的の達成に必要最小限の情報にとどめる。
不要な個人情報や機密情報を含めてはならない。

[対応: 5.6.B]

---

## 7. 出力の管理

### 7.1 ファクトチェック義務

AI出力を業務に利用する場合、事実情報
（数値、日付、法令名、人名、固有名詞等）は必ず一次情報源で確認する。
確認が困難な情報は「AI出力・未検証」と明示して共有する。

[対応: 4.1.A]

### 7.2 専門家レビュー

AI出力が以下の領域に関わる場合は、専門家によるレビューを必須とする：

- 法的判断・契約内容 → 顧問弁護士
- 財務・会計処理 → 顧問税理士
- 技術的な判断 → ITコンサルタント

[対応: 4.1.B]

### 7.3 そのまま使用してはならない場面

以下の場面ではAI出力をそのまま使用してはならない：

- 対外公式文書（契約書、プレスリリース、公式声明）
- 法的効力を持つ文書
- 人事評価・処遇に関する文書
- 顧客への最終的な助言・提案

これらの用途では草案としてのみ利用し、
必ず人間が加筆・修正・承認を行う。

[対応: 4.1.C]

### 7.4 人間による最終確認

AI出力の利用にあたっては、以下の承認プロセスを経る：

| 利用場面 | 承認プロセス |
|----------|--------------|
| 社内利用のみ | 利用者自身の確認 |
| 対外利用 | 上長の承認 |
| 重大な意思決定 | AI管理担当者の確認 |

[対応: 4.1.D, 4.4.A]

### 7.5 ハルシネーションへの対処

生成AIはもっともらしい誤情報を出力することがある（ハルシネーション）。
AI出力は必ず事実確認し、確認できない情報は「未検証」と明示する。

[対応: 5.1.A]

### 7.6 生成AIの限界

生成AIは以下の領域で誤りやすい：

- 最新の情報（学習データの時点以降）
- 正確な数値計算
- 専門的な法的・医学的判断
- ローカルな固有情報

これらの領域ではAI出力を参考程度にとどめる。

[対応: 5.1.B]

### 7.7 出力の信頼度の目安

| 用途 | 信頼度 | 対応 |
|------|--------|------|
| 一般知識の要約・翻訳 | 比較的高い | 確認は必要 |
| 専門分野・最新情報 | 低い | 必ず専門家・一次情報で確認 |
| 数値・固有名詞 | 低い | 必ず裏取り |

[対応: 5.1.C]

### 7.8 著作権の帰属

- AI出力をそのまま使用した場合は著作権が発生しない前提で扱う
- 人間が実質的な加筆・編集を行った場合は、編集者の著作物として扱う
- 利用するAIサービスの規約で生成物の権利帰属も確認する

[対応: 4.2.A]

### 7.9 既存著作物との類似性

AI生成物を対外利用する場合、既存著作物との類似性を可能な範囲で確認する。
画像は類似画像検索で確認し、文章は特徴的な表現の一致を検証する。

[対応: 4.2.B]

### 7.10 AI生成の表示

以下の場合はAI生成物であることを明示する：

- 社外向けコンテンツ（広報・マーケティング資料等）
- 顧客への提出物

明示の方法：文書末尾への注記
（例：「本文書の草案作成にAIを利用しています」）

[対応: 4.3.A]

### 7.11 社外向け資料

社外向け資料にAI出力を利用する場合：

1. 内容の正確性確認と人間による加筆・編集を必須とする
2. 上長の承認を得てから提出・公開する

[対応: 4.3.B]

### 7.12 顧客への説明責任

顧客・取引先への成果物にAIを活用した場合、
求めに応じてAI利用の事実を説明できるようにする。

[対応: 4.3.C]

### 7.13 安全に関わる業務での制限

法的判断、財務判断、健康に関する助言など、
誤りが重大な実害につながる業務では、
生成AIの出力を最終判断の唯一の根拠として使用してはならない。

[対応: 5.2.A]

### 7.14 人間の最終判断を要する場面

以下の場面ではAI出力にかかわらず人間が最終判断する：

- 顧客への助言・提案
- 契約・法的文書の作成
- 人事評価
- 対外公表物の内容確定

[対応: 5.2.B]

### 7.15 意思決定過程の説明

AIを活用した意思決定では、AI出力をどう参考にし
最終判断へ至ったかを関係者へ説明できるようにする。

[対応: 5.4.B]

### 7.16 根拠説明を要する場面

以下の場面ではAI出力の根拠を説明できること：

- 顧客への助言・提案
- 報告書・提出物の作成
- 組織の意思決定に関わる分析

[対応: 5.5.A]

### 7.17 説明困難な場合

AI出力の根拠を十分に説明できない場合は、
当該出力を意思決定の主要根拠としない。
補助的な参考にとどめ、別の情報源で裏付ける。

[対応: 5.5.B]

### 7.18 個人の権利への対応

AI利用に関して本人から開示・削除等の請求があった場合は、
個人情報保護方針に従い対応する。

[対応: 5.6.C]

---

## 8. 教育・研修

### 8.1 初回研修

生成AI利用開始前に全職員を対象とした初回研修（90分）を実施する。

**内容：**
- ガイドラインの要点
- 禁止事項
- 入力してはいけない情報の具体例
- インシデント報告手順

受講記録を管理し、未受講者にはAI利用権限を付与しない。

[対応: 1.3.A]

### 8.2 レベル別研修

| 対象 | 内容 |
|------|------|
| 全職員（基礎編） | AIの概要、リスク、禁止事項 |
| 日常利用者（実践編） | プロンプト設計、出力検証、業務活用事例 |

[対応: 1.3.B]

### 8.3 新規利用者のオンボーディング

新規入職者には、入職時オリエンテーションの一環として
AI利用ガイドラインの説明と基礎研修の受講を義務づける。
研修完了後にAIツールのアカウントを発行する。

[対応: 1.3.C]

### 8.4 継続的な啓発

四半期に1回、AI利用に関するミニ勉強会（30分）を実施し、
最新のリスク事例・活用好事例・ガイドライン改訂内容を共有する。
重大な外部事例が発生した場合は、速やかに全職員に注意喚起する。

[対応: 1.3.D]

### 8.5 バイアスに関する教育

生成AIの出力には学習データに由来するバイアス
（性別、人種、地域等の偏り）が含まれうる。
AI出力を評価や判断に用いる際はバイアスの可能性を意識する。

[対応: 5.7.A]

### 8.6 人事・採用でのAI利用

人事評価、採用選考、昇進判断等にAIを利用する場合は
バイアスによる差別が生じないよう特に注意し、
AI出力を唯一の判断基準としない。

[対応: 5.7.B]

### 8.7 セキュリティに関する注意喚起

外部から取得したテキスト（Webページ、メール等）を
AIへ入力する際は、悪意ある指示が埋め込まれている
可能性（プロンプトインジェクション）に注意する。
不審な出力があれば利用を中止し報告する。

[対応: 5.3.D]

---

## 9. インシデント対応

### 9.1 インシデントの定義

以下の事象をAIインシデントと定義する。
発見次第、エスカレーションルート（4.3項）に従い報告する：

- 機密情報・個人情報をAIに入力してしまった場合
- AI出力の誤情報を検証せず社外に提供してしまった場合

[対応: 6.1.A]

### 9.2 初動対応

AIインシデント発生時は以下の手順で対応する：

1. 当該AI出力の利用を即座に停止する
2. 社外に提供済みであれば提供先と内容を特定する
3. AI管理担当者の指示に基づき必要な措置（訂正・回収等）を講じる

[対応: 6.2.A]

### 9.3 外部報告

以下の場合は外部へ報告・連絡する：

- 個人情報の漏えいが疑われる場合 → 個人情報保護委員会へ報告
- 顧客に誤情報を提供した場合 → 速やかに訂正を連絡
- 利用規約違反の可能性がある場合 → AIサービス提供者へ確認

[対応: 6.2.B]

### 9.4 記録と改善

AIインシデント発生時は、発生日時・事象の概要・対応内容を簡潔に記録する。
記録はガイドライン見直しの際に振り返り、
再発傾向があれば運用ルールを改定する。

[対応: 6.3.A]

### 9.5 緊急停止基準

以下の場合はAI利用を即座に停止し責任者へ報告する：

- 情報漏えいの疑い
- サービス規約の重大変更
- 継続的な誤出力の発生

停止判断はAI管理責任者が行う。

[対応: 5.2.C]

---

## 10. 違反時の対応

違反を確認した場合、以下の対応を行う：

| 違反の程度 | 対応 |
|------------|------|
| 軽微な違反（過失による禁止情報の入力等） | 口頭注意と再研修 |
| 重大な違反（意図的な機密情報入力、悪用目的の利用等） | AI利用権限の停止、懲戒規定に基づき対応 |

すべての違反対応を記録する。

[対応: 1.4.C]

---

## 11. 運用・見直し

### 11.1 定期見直し

本ガイドラインは少なくとも年1回（毎年4月）に見直しを行う。
AIに関する重大な法改正やインシデント発生時には臨時の見直しを実施する。
見直しはAI管理担当者が起案し、最終責任者が承認する。

[対応: 1.2.E]

### 11.2 リスク許容度

| 業務 | AI利用可否 |
|------|------------|
| 公開情報の要約・翻訳支援（リスク低） | 許可 |
| 個人情報・機密情報を扱う業務 | 制限または禁止 |
| 対外的な意思決定に関わる業務 | 制限 |

判断が困難な場合はAI管理担当者の承認を得る。

[対応: 1.2.F]

### 11.3 リスク評価

以下のリスクを評価し、対策を講じている：

| リスク | 評価 | 対策 |
|--------|------|------|
| 情報漏えい | 高 | 入力禁止情報の明確化、海外サーバー利用時の個人データ入力禁止 |
| 著作権侵害 | 中 | 類似性確認、出典明記 |
| ハルシネーション | 高 | ファクトチェック義務化、専門家レビュー |
| プライバシー侵害 | 高 | 個人データ入力原則禁止、匿名化手順の整備 |
| セキュリティ | 中 | 承認済みサービスのみ利用、アカウント管理 |
| 法的リスク | 中 | 関連法令の周知、顧問弁護士への相談体制 |
| レピュテーションリスク | 中 | 対外公開前の人間によるレビュー必須 |
| 業務依存リスク | 低 | AIなしでも業務遂行可能な体制維持 |

[対応: 2.2.A, 2.2.B, 2.2.C, 2.2.D, 2.2.E, 2.2.F, 2.2.G, 2.2.H, 2.2.I]

### 11.4 サードパーティリスク管理

AIツールの選定にあたっては、以下を確認する：

- データの取扱方針（学習利用の有無）
- セキュリティ対策（通信暗号化、データ保存場所）
- 利用規約の内容
- 提供元の信頼性

[対応: 2.3.A]

導入前に利用規約・プライバシーポリシーを確認し、
重大な懸念がある場合は顧問弁護士に相談する。

[対応: 2.3.B]

各AIサービスの学習利用設定を確認・記録し、
オプトアウト設定がある場合は確実にオフに設定する。

[対応: 2.3.C]

### 11.5 サービス停止時の対応

主要AIツールの停止・大幅変更に備え：

- 代替ツールの候補を予め把握する
- 重要業務についてはAIなしでも遂行できる手順を維持する

サービス停止時はAI管理担当者が48時間以内に代替策を提示する。

[対応: 2.3.D, 1.4.E]

### 11.6 例外対応

ガイドラインの適用が業務上困難な場合は、
AI管理担当者に申請し最終責任者の承認を得た上で例外対応とする。
例外の内容と理由は記録し、次回見直し時に恒久対応を検討する。

[対応: 7.2.D]

---

## 12. 問い合わせ先

AI利用に関する質問・相談は以下に連絡すること。

| 担当 | 連絡先 |
|------|--------|
| AI管理担当者 | 総務部 ○○（内線: XXX、メール: ai-support@example.or.jp） |
| AI管理責任者 | 総務部長 △△（内線: YYY） |

[対応: 7.2.A, 7.2.B, 7.2.C]

### 関連文書

- 情報セキュリティポリシー
- 個人情報保護方針
- 就業規則

[対応: 7.1.D]

---

## 13. 改訂履歴

| 版 | 改訂日 | 改訂内容 |
|----|--------|----------|
| 1.0 | 2026年4月1日 | 初版制定 |

[対応: 7.3.A]

---

以上
